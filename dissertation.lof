\addvspace {10pt}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Overview of Computational Imaging. The forward model $\mathcal {A}$ is a function of the physical properties of light, the optical system design, and (mis)calibration of the system. An image of a Nikon TE300 microscope used in this work is provided for context.}}{3}{figure.1.1}% 
\contentsline {figure}{\numberline {1.2}{\ignorespaces Schematic of a 4$f$ optical system}}{4}{figure.1.2}% 
\contentsline {figure}{\numberline {1.3}{\ignorespaces Simulation of a convolutional forward model and verification of DNF calculations. Top row shows forward modal with additive gaussian noise, while the middle row shows the deconvolution of the same measurement, separated into object deconvolution and noise amplification terms. Bottom row shows the measurement and reconstruction SNR across 1000 random generations of the Gaussian white noise term, overlaid with the multiplication of the reconstruction SNR multiplied by the DNF as a verification. The operators $*$ and $*^{-1}$ represent 2D convolution and deconvolution, respectively.}}{8}{figure.1.3}% 
\contentsline {figure}{\numberline {1.4}{\ignorespaces Nikon TE300-based system used for most experiments presented in this dissertation consisting of a digital camera, programmable LED illumination source, and mechanical motion stage. Here, a quasi-domed illuminator is mounted in place of the conventional optical condenser, although this may be replaced with a single LED high-throughput imaging.}}{10}{figure.1.4}% 
\addvspace {10pt}
<<<<<<< HEAD
\contentsline {figure}{\numberline {2.1}{\ignorespaces Example transfer functions for typical half-circle illumination patterns.}}{13}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Differential Phase Contrast Reconstruction of a USAF 1951 resolution target printed as a phase object. The DPC linearization becomes less accurate for objects with strong phase ($> 1 rad$) or a strong phase gradient.}}{15}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Multi-contrast image of mouse kidney cells using a fluorescent actin stain, single darkfield measurement and four DPC measurements acquired serially using a Nikon TE2000. Dataset was acquired at Analytical and Quantitative Light Microscopy (AQLM) conference in 2017 with help from Justin Taraska (NIH) and Shalin Mehta (MBL)}}{16}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Single-shot color Differential Phase Contrast (\textit {cDPC}) microscopy. a) Installation in Nikon TE300 microscope condenser turret. b) CAD model and image of fabricated \textit {cDPC} insert.c) Optical schematic of a brightfield microscope with a \textit {cDPC} color filter placed at the back focal plane of the condenser in K\"{o}hler configuration. d) Reconstruction: the captured color image is separated into its RGB components, which are then used to recover two unknowns (amplitude and phase) via a well-posed linear deconvolution. The sample is a micro-lens array (Fresnel Technologies 605). }}{17}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Transfer functions for amplitude and phase contrast in each \textit {cDPC} color channel. Left: Spectral contribution of each illumination filter as captured by the camera's Bayer pattern. The following columns show the components of the amplitude and phase transfer functions in the spatial frequency domain and the source represented in each image. Bottom row: sum of each column, representing the calibrated and scaled source and the total coverage of amplitude and phase transfer functions, respectively. }}{19}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces Experimental comparison of single-shot \textit {cDPC} with monochromatic DPC and through-focus phase retrieval methods. (Left) Source patterns. (Middle) Raw camera measurements. (Right) Recovered optical field. DPC methods (partially coherent) were acquired using a 20$\times $ 0.4 NA objective lens, while through-focus images (spatially coherent) were captured using 60$\times $ 0.8 NA, in order to ensure equal resolution in all cases.}}{22}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces Phase and amplitude reconstructions for various samples and magnifications. (First column) Micro-lens array, 4x 0.1 NA. (Second column) Wild-type c. elegans, 10x 0.25 NA. (Third column) HEK 293T cells, 20$\times $ 0.4 NA). (Fourth column) MCF7 cells, 20$\times $ 0.4 NA.}}{23}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces Experimental demonstration of motion blur reduction with \textit {cDPC} vs. conventional DPC. The \textit {cDPC} method results in significantly reduced motion blur artifacts due to its single-shot acquisition.}}{24}{figure.2.8}% 
\contentsline {figure}{\numberline {2.9}{\ignorespaces Comparison of standard DIC and PhC images to their synthesized counterparts from \textit {cDPC}. Ground truth DIC images were acquired using a 20x 0.75 NA objective and phase contrast images using a 20x 0.4 NA PhC objective. \textit {cDPC} images were acquired using a 20x 0.4 NA objective and the filter insert.}}{25}{figure.2.9}% 
\contentsline {figure}{\numberline {2.10}{\ignorespaces DPC transfer functions for amplitude and phase for a range of source cavitation values. As illumination is removed from the center of the source, the overall spectrum becomes more normalized, leading to higher relative values across the mid-range spatial frequencies. However, signal is simultaneously reduced due to lower light throughput. The trade-off between better conditioning and light throughput depends on the illumination power per pixel (or per led).}}{26}{figure.2.10}% 
\contentsline {figure}{\numberline {2.11}{\ignorespaces Expected SNR of DPC reconstructions as a function of source cavitation. Source patterns with no cavitation generally provide nearly-optimal SNR, although a source with cavitation NA of approximately $NA \/ 2$ is optimal for high illuminance values.}}{27}{figure.2.11}% 
\contentsline {figure}{\numberline {2.12}{\ignorespaces Expected SNR of DPC reconstructions as a function of measurement count (equidistant angles). SNR increases with the square root of measurement count for more than three DPC measurements, which is the equivalent of averaging measurements under the same noise conditions. For two or less measurements, expected SNR decreases significantly, since there is not enough information to disambiguate phase and amplitude for all frequencies.}}{28}{figure.2.12}% 
\addvspace {10pt}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Illustration of ideal space-bandwidth product allocation for various common objective lenses as plotted in the WDF. While the area of each rectangle remains constant, the aspect ratio illustrates the allocation of bandwidth between high-resolution and a wide FOV.}}{34}{figure.3.1}% 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Comparison of spectral (Fourier-domain) and spatial (real-domain) scanning techniques in high-throughput systems in one dimension ($x$). The Wigner Distribution Function ($\mathbf {W}(\bm {x}, \bm {k_x})$) provides a visual representation of the scanning geometry of each approach.}}{35}{figure.3.2}% 
\contentsline {figure}{\numberline {3.3}{\ignorespaces High throughput imaging system with coded illumination. A.) Our system consists of an inverted optical fluorescence microscope with a 2-axis motion stage, illuminated using a programmable LED illumination source. In our proposed method, the sample is illuminated with many discrete pulses while being scanned at constant velocity. B.) Comparison between conventional high-throughput imaging techniques (stop-and-stare, strobed illumination) and our proposed coded illumination technique. Coded illumination provides a trade-off between SNR and acquisition speed, particularly for low-light situations such as fluorescence imaging. C.) Image of our system, which is a Nikon TE300 microscope configured with a Prior motion stage and LED illuminator.}}{36}{figure.3.3}% 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Multi-frame forward model. Here $[*]$ represents 2D convolution and $[\cdot ]$ represents the element-wise product. Top right inset is a an example of a full 1D multi-frame convolution matrix.}}{37}{figure.3.4}% 
\contentsline {figure}{\numberline {3.5}{\ignorespaces A.) Optimal DNF values for illumination patterns generated by different optimization methods show that random search over binary patterns is of comparable effectiveness to the projected gradient descent method. B.) Example illumination sequences show differing power spectra between constant illumination and patterns generated by random search over greyscale, random search over binary, and projected gradient descent. C.) Optimized DNF (binary random search method) is plotted over different values of $\gamma $. A power law fit of $f(\gamma ) = 1.12 \gamma ^{0.641}$ has standard error of $1.075$.}}{38}{figure.3.5}% 
\contentsline {figure}{\numberline {3.6}{\ignorespaces (1.18 gigapixel, 23mm $\times $ 20mm full-field reconstruction of 4.7$\mu m$ fluorescent microspheres. Inset scale bars are 50$\mu m$. While coded reconstructions have lower SNR than stop-and-stare (S\&S) measurements, measurements acquired using coded illumination (Coded) were more than 5.5$\times $ faster while maintaining enough signal to distinguish individual microspheres compared to strobed illumination (Strobed)}}{40}{figure.3.6}% 
\contentsline {figure}{\numberline {3.7}{\ignorespaces (Top) Experimental SNR values for a USAF 1951 resolution illuminated across a range of illumination values under strobed (square) and coded illumination (diamond). Solid lines illustrate predicted SNR based on known system parameters. Experimental SNR values are the average of 3 SNR measurements performed across the field. Green and orange data points represent inset data for fluorescent beads and resolution targets respectively. Characteristic illuminance values for LED sources, Halogen-Tungsten Lamps (Hal.), Mercury Lamps (Hg), Xenon Lamps (Xe), and Metal-Halide Lamps (M-H) are shown for reference. (Bottom) Selection of measurements used to generate the above plot. Scale bar is 25 $\mu m$.}}{45}{figure.3.7}% 
\contentsline {figure}{\numberline {3.8}{\ignorespaces Limiting Analysis of Imaging System. A.) Analysis pipeline for predicting SNR from system parameters, including illumination power, mechanical parameters of the motion stage, and camera noise parameters. B.) The stop-and-stare acquisition strategy is only possible for some configurations of mechanical system parameters and frame rates. C.) Different combinations of optical system parameters and system illuminance determine the best possible SNR and whether strobed or coded illumination is preferable. Characteristic illuminance values for LED sources, Halogen-Tungsten Lamps (Hal), Mercury Lamps (Hg), Xenon Lamp (Xe), and Metal-Halide Lamps (M-H) are shown for reference. }}{46}{figure.3.8}% 
\contentsline {figure}{\numberline {3.9}{\ignorespaces Limiting analysis of constraints imposed by the chemical fluorescence process, using contrast-to-noise ratio as the figure of merit. A.) Photobleaching influences the choice between coded and strobed illumination only when introducing a coding scheme would cause photobleaching, corresponding to a thin area of strobed optimality near the photobleaching limit. This plot assumes no background autofluorescence, so contrast-to-noise and SNR are equivalent. B.) The amount of autofluorescence relative to the signal mean has a slight effect on the optimality of strobed and coded illumination, but the effect is not strong relative to the other parameters studied here. Generally, the presence of autofluorescence degrades contrast-to-noise ratio significantly for all methods, for all illumination levels.}}{49}{figure.3.9}% 
\addvspace {10pt}
\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview of dome designs from the Adafruit 32$\times $32 planar LED array to the proposed quasi-domed device. Oru first iteration used a true domed geometry, increasing illumination power at high angles, but was very difficult to fabricate. A second iteration led to the quasi-domed array, which uses standard printed circuit board fabrication processes to make the dome easy to fabricate while maintaining the benefits of a domed geometry.}}{53}{figure.4.1}% 
\contentsline {figure}{\numberline {4.2}{\ignorespaces { Domed LED Illuminator.}{(a)} Illumination pattern used to acquire dark field images with a 0.25 NA objective. {(b)} Illumination pattern used to synthesize differential phase contrast images with a 0.25 NA objective. {(c)} Illustration of the arbitrary illumination patterning capabilities of the device. {(d)} Normalized mean pixel intensities measured at the sensor for the planar and domed arrays. Intensity decreases as a function of angle in both cases, but much more strongly in the case of the planar geometry. Values were normalized to the central LED's brightness in both cases. {(e)} Visual comparison of a planar LED array with a domed array. Since the intensity of a spherical wave drops as a function of the inverse square of radius, the illumination at the sample depends on the distance between the LEDs and the sample. In the planar case (left), LED distance $r$ increases as a function of illumination angle, causing weaker illumination at higher angles. A domed LED array (right) eliminates this variation ($r$ is constant). {(f)} Plot illustrating the relative objective NA for several common magnifications, as compared to our dome's LED placement (small black circles). {(g)} Normalized measured intensity falloff as a function of angle relative to the optical axis for the domed and planar LED arrays. Falloff is proportional to $\qopname \relax o{cos}(\theta )$ for the domed geometry and $\sim \qopname \relax o{cos}^4(\theta )$ for the planar geometry. Black lines are $\qopname \relax o{cos}(\theta )$ and $\qopname \relax o{cos}^4(\theta )$ fits for the domed and planar geometries, respectively. The domed geometry exhibits significant improvements in intensity at large angles of illumination. }}{55}{figure.4.2}% 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Quasi-dome programmable LED illuminator. (a) CAD model of LED flange positions. (b) Assembled LED array quasi-dome displaying two half circles (center line of LEDs are turned off). (c) Simulated intensity falloff of LED array considering all factors (normalized). (d) Experimental normalized intensity falloff.}}{56}{figure.4.3}% 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Circuit schematic for Quasi-dome device. A chain of up to 40 TLC5955 chips are connected in a daisy-chain configuration, having common Power (VCC), ground (GND), Grayscale-clock (GS), serial clock (SCLK), and latch (LAT) pins. These are controlled by a micro-controller upstream, which enables the control of up to $16 \times N_{tlc}$ LEDs for $N_{tlc}$ TLC5955 chips.}}{57}{figure.4.4}% 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Circuit schematic for fast LED driver circuit. A transistor (NPN type) is used to modulate a large current source for controlling many LEDs at once, which are connected in serial. Resistors R0 is normally set to 1K$\Omega $, and R1 is set such that the current is not too large based on the VCC voltage. This circuit enables micro-controller limited illumination updates, although it does not allow per-channel dimming and supports only binary illumination patterns.}}{58}{figure.4.5}% 
\contentsline {figure}{\numberline {4.6}{\ignorespaces {Computational CellScope.} {a).} Device observing a sample using a Nexus 4 smartphone. {b).} Optical schematic of the CellScope device with our custom-made domed LED illuminator. {c).} CAD assembly of the dome. {d).} Assembled dome and control circuitry.}}{60}{figure.4.6}% 
\contentsline {figure}{\numberline {4.7}{\ignorespaces {Image results compared to a standard microscope.} Computational CellScope acquires brightfield and darkfield images of similar quality to a standard upright microscope (Nikon TE300) without the use of hardware inserts. Additionally, it enables phase imaging using Differential Phase Contrast (DPC), which contains similar information to standard phase contrast imaging, and can be inverted to obtain quantitative phase of the sample (bottom row). Differences in color shades are caused by the relative differences in hue of the halogen lamp and the white LEDs. Note the additional dark features in DIC results, as compared to DPC, illustrating mixing of phase and absorption information in DIC. In the right-most column, we show images for an unstained transparent sample, illustrating the utility of phase imaging methods for label-free imaging. }}{61}{figure.4.7}% 
\contentsline {figure}{\numberline {4.8}{\ignorespaces {Digital refocusing on the Computational CellScope.} Comparison of digital refocusing to physical refocusing on a commercial microscope (Nikon TE300) of a house fly wing sample (AmScope PS200) with a 10$\times $ objective. Digitally refocused phase contrast images are also computed for both vertical and horizontal phase derivatives at different focus depths.}}{64}{figure.4.8}% 
\contentsline {figure}{\numberline {4.9}{\ignorespaces {Android Application Workflow.} {a).} Schematic of streaming multi-contrast LED patterns. Here we vary the LED pattern in time and acquire and process images on the smartphone, producing a streaming multi-contrast display of a sample without any further post-processing. The user can touch any image to zoom in and stream an individual image. Total cycle time is 2.3 seconds. {b).} Overview of workflow for digital refocusing mode. Table shows example processing and acquisition times for a typical dataset reconstruction. Axial Resolution is determined by the range of illumination angles sampled (defined by the objective NA). The number of z-steps were chosen such that refocus blur does not exceed 20 pixels. Processing and acquisition time can be reduced by selecting fewer refocus planes or by sparsely sampling LEDs, trading axial resolution for faster acquisition time.}}{67}{figure.4.9}% 
\addvspace {10pt}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Our LED array microscope captures 4 images with different illumination source patterns (three half-circles and one single LED). The intensity images are used to simultaneously reconstruct both amplitude and phase of the sample, and to estimate the pupil aberrations at each spatial location, which are then digitally corrected for. We show reconstructions for 4 regions with different spatially-varying aberrations.}}{71}{figure.5.1}% 
\contentsline {figure}{\numberline {5.2}{\ignorespaces Performance of joint phase and aberrations estimation on a simulated dataset. (a) Simulated FPM and DPC measurements. Red dashed circles indicate the $\mathrm {NA}$ of the objective lens. (b) Joint estimation of optical field and pupil aberrations, comparing ground truth, FPM and DPC measurements. (c) Errors for complex-field and aberrations at each iteration.}}{76}{figure.5.2}% 
\contentsline {figure}{\numberline {5.3}{\ignorespaces (a) Experimental FPM and DPC measurements for different LED source patterns. Zoomed regions at different orientations for coherent illumination are marked in cyan and pink boxes, respectively. (b) Quantitative phase of a star target using FPM and DPC, along with 1D cutlines for FPM (red) and DPC (blue) along the dashed lines. (c) Reconstructed wavefront error function and the weights of each Zernike mode up to the $4^{th}$ radial degree.}}{77}{figure.5.3}% 
\contentsline {figure}{\numberline {5.4}{\ignorespaces (a) Quantitative phase reconstructions of a USAF 1951 resolution target at various defocus distances with and without aberration correction, and the corresponding recovered aberrations (see Visualization 2). (b) Zoomed-in reconstructions at defocus of $10 \mu m$. (c) Known and experimentally-estimated defocus values from the $4^{th}$ Zernike mode over time.}}{79}{figure.5.4}% 
\contentsline {figure}{\numberline {5.5}{\ignorespaces (a) Reconstructed absorption, phase and spatially-varying aberrations (recovered pupil wavefronts for different regions of the field-of-view). (b) Comparison of results with and without pupil estimation for central and edge regions of the field-of-view.}}{80}{figure.5.5}% 
\contentsline {figure}{\numberline {5.6}{\ignorespaces Illumination angles are calibrated by analyzing Fourier spectra. (a) A cheek cell is illuminated at angle $\alpha $ and imaged with $NA_{obj}$. (b) Brightfield images contain overlapping circles in their Fourier spectra; darkfield images do not. (c) We perform a fast and efficient brightfield calibration in pre-processing, then extrapolate the correction to darkfield images and, finally, iteratively calibrate angles inside the FPM algorithm using a spectral correlation calibration. }}{82}{figure.5.6}% 
\contentsline {figure}{\numberline {5.7}{\ignorespaces Circular edge detection on brightfield images finds circle centers, giving illumination angle calibration. (a,b) Comparison of uncalibrated (red) and calibrated (black) illumination $\bm {k}_i$. The blue box in (b) indicates the search range for $\bm {k}_i$. (c,d) $\mathaccentV {tilde}07E{\bm {I}_i}$ along radial lines, $f(r,\phi _n)$, and derivatives with respect to $r$. (e,f) $\bm {E}_1$ and $\bm {E}_2$, sums of the derivatives at known radii $R$ and $R+\sigma $, peak near the correct center. Boxes show uncalibrated (red) and calibrated (black) $\bm {k}_i$ centers. }}{84}{figure.5.7}% 
\contentsline {figure}{\numberline {5.8}{\ignorespaces BF calibration uses a fast pre-processing step to estimate illumination angles, then SC calibration iteratively refines them within the FPM solver. (a) Algorithm block diagram, (b) uncalibrated (red) and BF + SC calibrated (green) illumination angle map. Insets are example search spaces, showing local convexity. (d) FPM convergence plot for different methods. }}{87}{figure.5.8}% 
\contentsline {figure}{\numberline {5.9}{\ignorespaces Experimental results with an LED array microscope, comparing reconstructions with no calibration (average reconstruction time 132 seconds), simulated annealing (3453 s), our BF calibration (156 s), and our BF + SC calibration (295 s). (a) Amplitude reconstructions of a USAF target in a well-aligned system. (b) Amplitude reconstructions of the same USAF target with a drop of oil placed on top of the sample to simulate sample-induced aberrations. (c) Phase reconstructions of a human cheek cell with computationally misaligned illumination, and (d) a Siemens star phase target with experimentally misaligned illumination. }}{89}{figure.5.9}% 
\contentsline {figure}{\numberline {5.10}{\ignorespaces Experimental angle calibration in laser and high-NA quasi-dome illumination systems. (a) Laser illumination is steered by a dual-axis galvanometer. The angled beam is relayed to the sample by 4", 80 mm focal length lenses. (b) Our calibration method removes low-frequency reconstruction artifacts. (c) The quasi-dome illuminator enables up to 0.98 $NA_{illum}$ using programmable LEDs. (d) Our 1.23 NA reconstruction provides isotropic 425 $nm$ resolution with BF + SC calibration. }}{90}{figure.5.10}% 
\contentsline {figure}{\numberline {5.11}{\ignorespaces Our calibration methods are robust to large mismatches between estimated and actual LED array position. Simulation of misaligned illumination by (a) rotation, (b) shift, and (c) scale. Our calibration recovers the illumination with <0.005 NA error for rotations of $-45^{\circ }$ to $45^{\circ }$, shifts of -0.1 to 0.1 NA, and scalings of 0.5$\times $ to 1.75$\times $ before diverging. }}{91}{figure.5.11}% 
\addvspace {10pt}
=======
\contentsline {figure}{\numberline {2.1}{\ignorespaces Overview of dome designs from the Adafruit 32$\times $32 LED array to the proposed quasi-domed device. Example LED distances are provided in red.}}{13}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces { Domed LED Illuminator.}{a)} Illumination pattern used to acquire dark field images with a 0.25 NA objective. {b)} Illumination pattern used to synthesize differential phase contrast images with a 0.25 NA objective. {c)} Illustration of the arbitrary illumination patterning capabilities of the device. {d)} Normalized mean pixel intensities measured at the sensor for the planar and domed arrays. Intensity decreases as a function of angle in both cases, but much more strongly in the case of the planar geometry. Values were normalized to the central LED's brightness in both cases. {e)} Visual comparison of a planar LED array with a domed array. Since the intensity of a spherical wave drops as a function of the inverse square of radius, the illumination at the sample depends on the distance between the LEDs and the sample. In the planar case (left), LED distance $r$ increases as a function of illumination angle, causing weaker illumination at higher angles. A domed LED array (right) eliminates this variation ($r$ is constant). {f)} Plot illustrating the relative objective NA for several common magnifications, as compared to our dome's LED placement (small black circles). {g)} Normalized measured intensity falloff as a function of angle relative to the optical axis for the domed and planar LED arrays. Falloff is proportional to $\qopname \relax o{cos}(\theta )$ for the domed geometry and $\sim \qopname \relax o{cos}^4(\theta )$ for the planar geometry. Black lines are $\qopname \relax o{cos}(\theta )$ and $\qopname \relax o{cos}^4(\theta )$ fits for the domed and planar geometries, respectively. The domed geometry exhibits significant improvements in intensity at large angles of illumination. }}{15}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Quasi-dome programmable LED illuminator. (a) CAD model of LED flange positions. (b) Assembled LED array quasi-dome displaying two half circles (center line of LEDs are turned off). (c) Simulated intensity falloff of LED array considering all factors (normalized). (d) Experimental normalized intensity falloff.}}{16}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Circuit schematic for Quasi-dome device. A chain of up to 40 TLC5955 chips are connected in a daisy-chain configuration, having common Power (VCC), ground (GND), Grayscale-clock (GS), serial clock (SCLK), and latch (LAT) pins. These are controlled by a micro-controller upstream, which enables the control of up to $16 \times N_{tlc}$ LEDs for $N_{tlc}$ TLC5955 chips.}}{17}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Circuit schematic for fast LED driver circuit. A transistor (NPN type) is used to modulate a large current source for controlling many LEDs at once, which are connected in serial. Resistors R0 is normally set to 1K$\Omega $, and R1 is set such that the current is not too large based on the VCC voltage. This circuit enables micro-controller limited illumination updates, although it does not allow per-channel dimming and supports only binary illumination patterns.}}{18}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces {Computational CellScope.} {a).} Device observing a sample using a Nexus 4 smartphone. {b).} Optical schematic of the CellScope device with our custom-made domed LED illuminator. {c).} CAD assembly of the dome. {d).} Assembled dome and control circuitry.}}{20}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces {Image Results Compared to a Standard Microscope.} Computational CellScope acquires brightfield and darkfield images of similar quality to a standard upright microscope (Nikon TE300) without the use of hardware inserts. Additionally, it enables phase imaging using Differential Phase Contrast (DPC), which contains similar information to standard phase contrast imaging, and can be inverted to obtain quantitative phase of the sample (bottom row). Differences in color shades are caused by the relative differences in hue of the halogen lamp and the white LEDs. Note the additional dark features in DIC results, as compared to DPC, illustrating mixing of phase and absorption information in DIC. In the rightmost column, we show images for an unstained transparent sample, illustrating the utility of phase imaging methods for label-free imaging. }}{21}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces {Digital refocusing on the Computational CellScope.} Comparison of digital refocusing to physical refocusing on a commercial microscope (Nikon TE300) of a house fly wing sample (AmScope PS200) with a 10$\times $ objective. Digitally refocused phase contrast images are also computed for both vertical and horizontal phase derivatives at different focus depths.}}{24}{figure.2.8}% 
\contentsline {figure}{\numberline {2.9}{\ignorespaces {Android Application Workflow.} {a).} Schematic of streaming multi-contrast LED patterns. Here we vary the LED pattern in time and acquire and process images on the smartphone, producing a streaming multi-contrast display of a sample without any further post-processing. The user can touch any image to zoom in and stream an individual image. Total cycle time is 2.3 seconds. {b).} Overview of workflow for digital refocusing mode. Table shows example processing and acquisition times for a typical dataset reconstruction. Axial Resolution is determined by the range of illumination angles sampled (defined by the objective NA). The number of z-steps were chosen such that refocus blur does not exceed 20 pixels. Processing and acquisition time can be reduced by selecting fewer refocus planes or by sparsely sampling LEDs, trading axial resolution for faster acquisition time.}}{26}{figure.2.9}% 
>>>>>>> 2b4d4a34b470c032a00705f35a2233c36459a5a8
\addvspace {10pt}
