\addvspace {10pt}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Overview of Computational Imaging. The forward model $\mathcal {A}$ is a function of the physical properties of light, the optical system design, and (mis)calibration of the system. An image of a Nikon TE300 microscope used in this work is provided for context.}}{3}{figure.1.1}% 
\contentsline {figure}{\numberline {1.2}{\ignorespaces Schematic of a 4$f$ optical system}}{4}{figure.1.2}% 
\contentsline {figure}{\numberline {1.3}{\ignorespaces Simulation of a convolutional forward model and verification of DNF calculations. Top row shows forward modal with additive gaussian noise, while the middle row shows the deconvolution of the same measurement, separated into object deconvolution and noise amplification terms. Bottom row shows the measurement and reconstruction SNR across 1000 random generations of the Gaussian white noise term, overlaid with the multiplication of the reconstruction SNR multiplied by the DNF as a verification. The operators $*$ and $*^{-1}$ represent 2D convolution and deconvolution, respectively.}}{8}{figure.1.3}% 
\contentsline {figure}{\numberline {1.4}{\ignorespaces Nikon TE300-based system used for most experiments presented in this dissertation consisting of a digital camera, programmable LED illumination source, and mechanical motion stage. Here, a quasi-domed illuminator is mounted in place of the conventional optical condenser, although this may be replaced with a single LED high-throughput imaging.}}{10}{figure.1.4}% 
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Overview of dome designs from the Adafruit 32$\times $32 LED array to the proposed quasi-domed device. Example LED distances are provided in red.}}{13}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces { Domed LED Illuminator.}{a)} Illumination pattern used to acquire dark field images with a 0.25 NA objective. {b)} Illumination pattern used to synthesize differential phase contrast images with a 0.25 NA objective. {c)} Illustration of the arbitrary illumination patterning capabilities of the device. {d)} Normalized mean pixel intensities measured at the sensor for the planar and domed arrays. Intensity decreases as a function of angle in both cases, but much more strongly in the case of the planar geometry. Values were normalized to the central LED's brightness in both cases. {e)} Visual comparison of a planar LED array with a domed array. Since the intensity of a spherical wave drops as a function of the inverse square of radius, the illumination at the sample depends on the distance between the LEDs and the sample. In the planar case (left), LED distance $r$ increases as a function of illumination angle, causing weaker illumination at higher angles. A domed LED array (right) eliminates this variation ($r$ is constant). {f)} Plot illustrating the relative objective NA for several common magnifications, as compared to our dome's LED placement (small black circles). {g)} Normalized measured intensity falloff as a function of angle relative to the optical axis for the domed and planar LED arrays. Falloff is proportional to $\qopname \relax o{cos}(\theta )$ for the domed geometry and $\sim \qopname \relax o{cos}^4(\theta )$ for the planar geometry. Black lines are $\qopname \relax o{cos}(\theta )$ and $\qopname \relax o{cos}^4(\theta )$ fits for the domed and planar geometries, respectively. The domed geometry exhibits significant improvements in intensity at large angles of illumination. }}{15}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Quasi-dome programmable LED illuminator. (a) CAD model of LED flange positions. (b) Assembled LED array quasi-dome displaying two half circles (center line of LEDs are turned off). (c) Simulated intensity falloff of LED array considering all factors (normalized). (d) Experimental normalized intensity falloff.}}{16}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Circuit schematic for Quasi-dome device. A chain of up to 40 TLC5955 chips are connected in a daisy-chain configuration, having common Power (VCC), ground (GND), Grayscale-clock (GS), serial clock (SCLK), and latch (LAT) pins. These are controlled by a micro-controller upstream, which enables the control of up to $16 \times N_{tlc}$ LEDs for $N_{tlc}$ TLC5955 chips.}}{17}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Circuit schematic for fast LED driver circuit. A transistor (NPN type) is used to modulate a large current source for controlling many LEDs at once, which are connected in serial. Resistors R0 is normally set to 1K$\Omega $, and R1 is set such that the current is not too large based on the VCC voltage. This circuit enables micro-controller limited illumination updates, although it does not allow per-channel dimming and supports only binary illumination patterns.}}{18}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces {Computational CellScope.} {a).} Device observing a sample using a Nexus 4 smartphone. {b).} Optical schematic of the CellScope device with our custom-made domed LED illuminator. {c).} CAD assembly of the dome. {d).} Assembled dome and control circuitry.}}{20}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces {Image Results Compared to a Standard Microscope.} Computational CellScope acquires brightfield and darkfield images of similar quality to a standard upright microscope (Nikon TE300) without the use of hardware inserts. Additionally, it enables phase imaging using Differential Phase Contrast (DPC), which contains similar information to standard phase contrast imaging, and can be inverted to obtain quantitative phase of the sample (bottom row). Differences in color shades are caused by the relative differences in hue of the halogen lamp and the white LEDs. Note the additional dark features in DIC results, as compared to DPC, illustrating mixing of phase and absorption information in DIC. In the rightmost column, we show images for an unstained transparent sample, illustrating the utility of phase imaging methods for label-free imaging. }}{21}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces {Digital refocusing on the Computational CellScope.} Comparison of digital refocusing to physical refocusing on a commercial microscope (Nikon TE300) of a house fly wing sample (AmScope PS200) with a 10$\times $ objective. Digitally refocused phase contrast images are also computed for both vertical and horizontal phase derivatives at different focus depths.}}{24}{figure.2.8}% 
\contentsline {figure}{\numberline {2.9}{\ignorespaces {Android Application Workflow.} {a).} Schematic of streaming multi-contrast LED patterns. Here we vary the LED pattern in time and acquire and process images on the smartphone, producing a streaming multi-contrast display of a sample without any further post-processing. The user can touch any image to zoom in and stream an individual image. Total cycle time is 2.3 seconds. {b).} Overview of workflow for digital refocusing mode. Table shows example processing and acquisition times for a typical dataset reconstruction. Axial Resolution is determined by the range of illumination angles sampled (defined by the objective NA). The number of z-steps were chosen such that refocus blur does not exceed 20 pixels. Processing and acquisition time can be reduced by selecting fewer refocus planes or by sparsely sampling LEDs, trading axial resolution for faster acquisition time.}}{26}{figure.2.9}% 
\addvspace {10pt}
